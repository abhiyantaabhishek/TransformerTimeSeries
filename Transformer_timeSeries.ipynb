{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer_timeSeries.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN/MbTnhe6viuhlngFuEbNe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhiyantaabhishek/TransformerTimeSeries/blob/master/Transformer_timeSeries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDoIYdxJ_mXC"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "from matplotlib import pyplot\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "# This concept is also called teacher forceing. \n",
        "# The flag decides if the loss will be calculted over all \n",
        "# or just the predicted values.\n",
        "calculate_loss_over_all_values = False\n",
        "\n",
        "# S is the source sequence length\n",
        "# T is the target sequence length\n",
        "# N is the batch size\n",
        "# E is the feature number\n",
        "\n",
        "#src = torch.rand((10, 32, 512)) # (S,N,E) \n",
        "#tgt = torch.rand((20, 32, 512)) # (T,N,E)\n",
        "#out = transformer_model(src, tgt)\n",
        "#\n",
        "#print(out)\n",
        "\n",
        "input_window = 100\n",
        "output_window = 5\n",
        "batch_size = 10 # batch size\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPhPiFJyAQS-"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()       \n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        #pe.requires_grad = False\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:x.size(0), :]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwbhvidUAVKx"
      },
      "source": [
        "class TransAm(nn.Module):\n",
        "    def __init__(self,feature_size=250,num_layers=1,dropout=0.1):\n",
        "        super(TransAm, self).__init__()\n",
        "        self.model_type = 'Transformer'\n",
        "        \n",
        "        self.src_mask = None\n",
        "        self.pos_encoder = PositionalEncoding(feature_size)\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_size, nhead=10, dropout=dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)        \n",
        "        self.decoder = nn.Linear(feature_size,1)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1    \n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self,src):\n",
        "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
        "            device = src.device\n",
        "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
        "            self.src_mask = mask\n",
        "\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src,self.src_mask)#, self.src_mask)\n",
        "        output = self.decoder(output)\n",
        "        return output\n",
        "\n",
        "    def _generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-yKb7FYAZ-9"
      },
      "source": [
        "# if window is 100 and prediction step is 1\n",
        "# in -> [0..99]\n",
        "# target -> [1..100]\n",
        "def create_inout_sequences(input_data, tw):\n",
        "    inout_seq = []\n",
        "    L = len(input_data)\n",
        "    for i in range(L-tw):\n",
        "        train_seq = np.append(input_data[i:i+tw][:-output_window] , output_window * [0])\n",
        "        train_label = input_data[i:i+tw]\n",
        "        #train_label = input_data[i+output_window:i+tw+output_window]\n",
        "        inout_seq.append((train_seq ,train_label))\n",
        "    return torch.FloatTensor(inout_seq)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f585ZPhiAdua"
      },
      "source": [
        "def get_data():\n",
        "    time        = np.arange(0, 400, 0.1)\n",
        "    amplitude   = np.sin(time) + np.sin(time*0.05) +np.sin(time*0.12) *np.random.normal(-0.2, 0.2, len(time))\n",
        "    \n",
        "    #from pandas import read_csv\n",
        "    #series = read_csv('daily-min-temperatures.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
        "    \n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "    scaler = MinMaxScaler(feature_range=(-1, 1)) \n",
        "    #amplitude = scaler.fit_transform(series.to_numpy().reshape(-1, 1)).reshape(-1)\n",
        "    amplitude = scaler.fit_transform(amplitude.reshape(-1, 1)).reshape(-1)\n",
        "    \n",
        "    \n",
        "    sampels = 2800\n",
        "    train_data = amplitude[:sampels]\n",
        "    test_data = amplitude[sampels:]\n",
        "\n",
        "    # convert our train data into a pytorch train tensor\n",
        "    #train_tensor = torch.FloatTensor(train_data).view(-1)\n",
        "    # todo: add comment.. \n",
        "    train_sequence = create_inout_sequences(train_data,input_window)\n",
        "    train_sequence = train_sequence[:-output_window] #todo: fix hack?\n",
        "\n",
        "    #test_data = torch.FloatTensor(test_data).view(-1) \n",
        "    test_data = create_inout_sequences(test_data,input_window)\n",
        "    test_data = test_data[:-output_window] #todo: fix hack?\n",
        "\n",
        "    return train_sequence.to(device),test_data.to(device)\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgZ_15ZrAhB5"
      },
      "source": [
        "def get_batch(source, i,batch_size):\n",
        "    seq_len = min(batch_size, len(source) - 1 - i)\n",
        "    data = source[i:i+seq_len]    \n",
        "    input = torch.stack(torch.stack([item[0] for item in data]).chunk(input_window,1)) # 1 is feature size\n",
        "    target = torch.stack(torch.stack([item[1] for item in data]).chunk(input_window,1))\n",
        "    return input, target"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIrEC5lmAkfR"
      },
      "source": [
        "\n",
        "def train(train_data):\n",
        "    model.train() # Turn on the train mode\n",
        "    total_loss = 0.\n",
        "    start_time = time.time()\n",
        "\n",
        "    for batch, i in enumerate(range(0, len(train_data) - 1, batch_size)):\n",
        "        data, targets = get_batch(train_data, i,batch_size)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)        \n",
        "\n",
        "        if calculate_loss_over_all_values:\n",
        "            loss = criterion(output, targets)\n",
        "        else:\n",
        "            loss = criterion(output[-output_window:], targets[-output_window:])\n",
        "    \n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        log_interval = int(len(train_data) / batch_size / 5)\n",
        "        if batch % log_interval == 0 and batch > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
        "                  'lr {:02.6f} | {:5.2f} ms | '\n",
        "                  'loss {:5.5f} | ppl {:8.2f}'.format(\n",
        "                    epoch, batch, len(train_data) // batch_size, scheduler.get_lr()[0],\n",
        "                    elapsed * 1000 / log_interval,\n",
        "                    cur_loss, math.exp(cur_loss)))\n",
        "            total_loss = 0\n",
        "            start_time = time.time()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7N89Vx2kApxX"
      },
      "source": [
        "def plot_and_loss(eval_model, data_source,epoch):\n",
        "    eval_model.eval() \n",
        "    total_loss = 0.\n",
        "    test_result = torch.Tensor(0)    \n",
        "    truth = torch.Tensor(0)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(data_source) - 1):\n",
        "            data, target = get_batch(data_source, i,1)\n",
        "            # look like the model returns static values for the output window\n",
        "            output = eval_model(data)    \n",
        "            if calculate_loss_over_all_values:                                \n",
        "                total_loss += criterion(output, target).item()\n",
        "            else:\n",
        "                total_loss += criterion(output[-output_window:], target[-output_window:]).item()\n",
        "            \n",
        "            test_result = torch.cat((test_result, output[-1].view(-1).cpu()), 0) #todo: check this. -> looks good to me\n",
        "            truth = torch.cat((truth, target[-1].view(-1).cpu()), 0)\n",
        "            \n",
        "    #test_result = test_result.cpu().numpy()\n",
        "    len(test_result)\n",
        "\n",
        "    pyplot.plot(test_result,color=\"red\")\n",
        "    pyplot.plot(truth[:500],color=\"blue\")\n",
        "    pyplot.plot(test_result-truth,color=\"green\")\n",
        "    pyplot.grid(True, which='both')\n",
        "    pyplot.axhline(y=0, color='k')\n",
        "    pyplot.savefig('graph/transformer-epoch%d.png'%epoch)\n",
        "    pyplot.close()\n",
        "    \n",
        "    return total_loss / i\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odpeKyPmAtB7"
      },
      "source": [
        "def predict_future(eval_model, data_source,steps):\n",
        "    eval_model.eval() \n",
        "    total_loss = 0.\n",
        "    test_result = torch.Tensor(0)    \n",
        "    truth = torch.Tensor(0)\n",
        "    _ , data = get_batch(data_source, 0,1)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, steps,1):\n",
        "            input = torch.clone(data[-input_window:])\n",
        "            input[-output_window:] = 0     \n",
        "            output = eval_model(data[-input_window:])                        \n",
        "            data = torch.cat((data, output[-1:]))\n",
        "            \n",
        "    data = data.cpu().view(-1)\n",
        "    \n",
        "\n",
        "    pyplot.plot(data,color=\"red\")       \n",
        "    pyplot.plot(data[:input_window],color=\"blue\")\n",
        "    pyplot.grid(True, which='both')\n",
        "    pyplot.axhline(y=0, color='k')\n",
        "    pyplot.savefig('graph/transformer-future%d.png'%steps)\n",
        "    pyplot.close()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlsMA5U4AxrJ"
      },
      "source": [
        "def evaluate(eval_model, data_source):\n",
        "    eval_model.eval() # Turn on the evaluation mode\n",
        "    total_loss = 0.\n",
        "    eval_batch_size = 1000\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(data_source) - 1, eval_batch_size):\n",
        "            data, targets = get_batch(data_source, i,eval_batch_size)\n",
        "            output = eval_model(data)            \n",
        "            if calculate_loss_over_all_values:\n",
        "                total_loss += len(data[0])* criterion(output, targets).cpu().item()\n",
        "            else:                                \n",
        "                total_loss += len(data[0])* criterion(output[-output_window:], targets[-output_window:]).cpu().item()            \n",
        "    return total_loss / len(data_source)\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skqWhfjsBGAB",
        "outputId": "4c2246eb-c946-4de9-a4b9-07d0009de29b"
      },
      "source": [
        "train_data, val_data = get_data()\n",
        "model = TransAm().to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "lr = 0.005 \n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.98)\n",
        "\n",
        "best_val_loss = float(\"inf\")\n",
        "epochs = 100 # The number of epochs\n",
        "best_model = None\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_data)\n",
        "    \n",
        "    \n",
        "    if(epoch % 10 is 0):\n",
        "        val_loss = plot_and_loss(model, val_data,epoch)\n",
        "        predict_future(model, val_data,200)\n",
        "    else:\n",
        "        val_loss = evaluate(model, val_data)\n",
        "        \n",
        "    print('-' * 89)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.5f} | valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
        "                                     val_loss, math.exp(val_loss)))\n",
        "    print('-' * 89)\n",
        "\n",
        "    #if val_loss < best_val_loss:\n",
        "    #    best_val_loss = val_loss\n",
        "    #    best_model = model\n",
        "\n",
        "    scheduler.step() \n",
        "\n",
        "#src = torch.rand(input_window, batch_size, 1) # (source sequence length,batch size,feature number) \n",
        "#out = model(src)\n",
        "#\n",
        "#print(out)\n",
        "#print(out.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch   1 |    53/  269 batches | lr 0.005000 | 193.70 ms | loss 5.48596 | ppl   241.28\n",
            "| epoch   1 |   106/  269 batches | lr 0.005000 | 204.43 ms | loss 0.14554 | ppl     1.16\n",
            "| epoch   1 |   159/  269 batches | lr 0.005000 | 208.47 ms | loss 0.10455 | ppl     1.11\n",
            "| epoch   1 |   212/  269 batches | lr 0.005000 | 192.35 ms | loss 0.12240 | ppl     1.13\n",
            "| epoch   1 |   265/  269 batches | lr 0.005000 | 187.36 ms | loss 0.09453 | ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 59.39s | valid loss 0.17054 | valid ppl     1.19\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   2 |    53/  269 batches | lr 0.004802 | 214.32 ms | loss 0.12637 | ppl     1.13\n",
            "| epoch   2 |   106/  269 batches | lr 0.004802 | 202.00 ms | loss 0.07405 | ppl     1.08\n",
            "| epoch   2 |   159/  269 batches | lr 0.004802 | 200.26 ms | loss 0.10025 | ppl     1.11\n",
            "| epoch   2 |   212/  269 batches | lr 0.004802 | 195.99 ms | loss 0.06594 | ppl     1.07\n",
            "| epoch   2 |   265/  269 batches | lr 0.004802 | 194.32 ms | loss 0.02727 | ppl     1.03\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 59.32s | valid loss 0.33240 | valid ppl     1.39\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   3 |    53/  269 batches | lr 0.004706 | 193.65 ms | loss 0.04816 | ppl     1.05\n",
            "| epoch   3 |   106/  269 batches | lr 0.004706 | 189.65 ms | loss 0.01897 | ppl     1.02\n",
            "| epoch   3 |   159/  269 batches | lr 0.004706 | 189.30 ms | loss 0.02184 | ppl     1.02\n",
            "| epoch   3 |   212/  269 batches | lr 0.004706 | 190.04 ms | loss 0.02233 | ppl     1.02\n",
            "| epoch   3 |   265/  269 batches | lr 0.004706 | 194.11 ms | loss 0.01844 | ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 56.57s | valid loss 0.41527 | valid ppl     1.51\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   4 |    53/  269 batches | lr 0.004612 | 193.78 ms | loss 0.04942 | ppl     1.05\n",
            "| epoch   4 |   106/  269 batches | lr 0.004612 | 188.05 ms | loss 0.02024 | ppl     1.02\n",
            "| epoch   4 |   159/  269 batches | lr 0.004612 | 186.58 ms | loss 0.01198 | ppl     1.01\n",
            "| epoch   4 |   212/  269 batches | lr 0.004612 | 187.59 ms | loss 0.01558 | ppl     1.02\n",
            "| epoch   4 |   265/  269 batches | lr 0.004612 | 190.54 ms | loss 0.01451 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 56.03s | valid loss 0.42446 | valid ppl     1.53\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   5 |    53/  269 batches | lr 0.004520 | 190.90 ms | loss 0.03699 | ppl     1.04\n",
            "| epoch   5 |   106/  269 batches | lr 0.004520 | 187.36 ms | loss 0.02361 | ppl     1.02\n",
            "| epoch   5 |   159/  269 batches | lr 0.004520 | 186.67 ms | loss 0.01184 | ppl     1.01\n",
            "| epoch   5 |   212/  269 batches | lr 0.004520 | 187.02 ms | loss 0.01443 | ppl     1.01\n",
            "| epoch   5 |   265/  269 batches | lr 0.004520 | 187.06 ms | loss 0.01115 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 55.59s | valid loss 0.41340 | valid ppl     1.51\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   6 |    53/  269 batches | lr 0.004429 | 189.70 ms | loss 0.02584 | ppl     1.03\n",
            "| epoch   6 |   106/  269 batches | lr 0.004429 | 187.87 ms | loss 0.01389 | ppl     1.01\n",
            "| epoch   6 |   159/  269 batches | lr 0.004429 | 189.07 ms | loss 0.01365 | ppl     1.01\n",
            "| epoch   6 |   212/  269 batches | lr 0.004429 | 188.02 ms | loss 0.01629 | ppl     1.02\n",
            "| epoch   6 |   265/  269 batches | lr 0.004429 | 186.54 ms | loss 0.01305 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time: 55.69s | valid loss 0.39629 | valid ppl     1.49\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   7 |    53/  269 batches | lr 0.004341 | 190.43 ms | loss 0.03476 | ppl     1.04\n",
            "| epoch   7 |   106/  269 batches | lr 0.004341 | 186.97 ms | loss 0.01295 | ppl     1.01\n",
            "| epoch   7 |   159/  269 batches | lr 0.004341 | 187.03 ms | loss 0.01403 | ppl     1.01\n",
            "| epoch   7 |   212/  269 batches | lr 0.004341 | 188.18 ms | loss 0.01337 | ppl     1.01\n",
            "| epoch   7 |   265/  269 batches | lr 0.004341 | 190.31 ms | loss 0.01348 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time: 55.80s | valid loss 0.38433 | valid ppl     1.47\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   8 |    53/  269 batches | lr 0.004254 | 191.60 ms | loss 0.03449 | ppl     1.04\n",
            "| epoch   8 |   106/  269 batches | lr 0.004254 | 187.84 ms | loss 0.01601 | ppl     1.02\n",
            "| epoch   8 |   159/  269 batches | lr 0.004254 | 186.99 ms | loss 0.01057 | ppl     1.01\n",
            "| epoch   8 |   212/  269 batches | lr 0.004254 | 185.53 ms | loss 0.01165 | ppl     1.01\n",
            "| epoch   8 |   265/  269 batches | lr 0.004254 | 184.94 ms | loss 0.01084 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time: 55.45s | valid loss 0.32563 | valid ppl     1.38\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   9 |    53/  269 batches | lr 0.004169 | 187.24 ms | loss 0.03061 | ppl     1.03\n",
            "| epoch   9 |   106/  269 batches | lr 0.004169 | 183.62 ms | loss 0.01382 | ppl     1.01\n",
            "| epoch   9 |   159/  269 batches | lr 0.004169 | 183.78 ms | loss 0.00963 | ppl     1.01\n",
            "| epoch   9 |   212/  269 batches | lr 0.004169 | 184.50 ms | loss 0.01131 | ppl     1.01\n",
            "| epoch   9 |   265/  269 batches | lr 0.004169 | 185.42 ms | loss 0.01070 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time: 54.76s | valid loss 0.32095 | valid ppl     1.38\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  10 |    53/  269 batches | lr 0.004085 | 188.89 ms | loss 0.03298 | ppl     1.03\n",
            "| epoch  10 |   106/  269 batches | lr 0.004085 | 187.26 ms | loss 0.01206 | ppl     1.01\n",
            "| epoch  10 |   159/  269 batches | lr 0.004085 | 183.13 ms | loss 0.01001 | ppl     1.01\n",
            "| epoch  10 |   212/  269 batches | lr 0.004085 | 183.59 ms | loss 0.01075 | ppl     1.01\n",
            "| epoch  10 |   265/  269 batches | lr 0.004085 | 184.62 ms | loss 0.00886 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time: 58.49s | valid loss 0.26500 | valid ppl     1.30\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  11 |    53/  269 batches | lr 0.004004 | 189.40 ms | loss 0.02668 | ppl     1.03\n",
            "| epoch  11 |   106/  269 batches | lr 0.004004 | 185.92 ms | loss 0.01251 | ppl     1.01\n",
            "| epoch  11 |   159/  269 batches | lr 0.004004 | 185.23 ms | loss 0.00995 | ppl     1.01\n",
            "| epoch  11 |   212/  269 batches | lr 0.004004 | 185.88 ms | loss 0.00929 | ppl     1.01\n",
            "| epoch  11 |   265/  269 batches | lr 0.004004 | 184.95 ms | loss 0.00973 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  11 | time: 55.11s | valid loss 0.25575 | valid ppl     1.29\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  12 |    53/  269 batches | lr 0.003924 | 186.59 ms | loss 0.02663 | ppl     1.03\n",
            "| epoch  12 |   106/  269 batches | lr 0.003924 | 183.95 ms | loss 0.00715 | ppl     1.01\n",
            "| epoch  12 |   159/  269 batches | lr 0.003924 | 184.04 ms | loss 0.00904 | ppl     1.01\n",
            "| epoch  12 |   212/  269 batches | lr 0.003924 | 182.94 ms | loss 0.01052 | ppl     1.01\n",
            "| epoch  12 |   265/  269 batches | lr 0.003924 | 183.67 ms | loss 0.00768 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  12 | time: 54.56s | valid loss 0.25661 | valid ppl     1.29\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  13 |    53/  269 batches | lr 0.003845 | 186.05 ms | loss 0.02870 | ppl     1.03\n",
            "| epoch  13 |   106/  269 batches | lr 0.003845 | 184.35 ms | loss 0.01129 | ppl     1.01\n",
            "| epoch  13 |   159/  269 batches | lr 0.003845 | 185.13 ms | loss 0.00871 | ppl     1.01\n",
            "| epoch  13 |   212/  269 batches | lr 0.003845 | 184.66 ms | loss 0.00923 | ppl     1.01\n",
            "| epoch  13 |   265/  269 batches | lr 0.003845 | 185.54 ms | loss 0.00905 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  13 | time: 54.79s | valid loss 0.25567 | valid ppl     1.29\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  14 |    53/  269 batches | lr 0.003768 | 187.31 ms | loss 0.03380 | ppl     1.03\n",
            "| epoch  14 |   106/  269 batches | lr 0.003768 | 182.78 ms | loss 0.01083 | ppl     1.01\n",
            "| epoch  14 |   159/  269 batches | lr 0.003768 | 182.64 ms | loss 0.00939 | ppl     1.01\n",
            "| epoch  14 |   212/  269 batches | lr 0.003768 | 181.69 ms | loss 0.00928 | ppl     1.01\n",
            "| epoch  14 |   265/  269 batches | lr 0.003768 | 181.36 ms | loss 0.00897 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  14 | time: 54.22s | valid loss 0.28334 | valid ppl     1.33\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  15 |    53/  269 batches | lr 0.003693 | 187.08 ms | loss 0.02776 | ppl     1.03\n",
            "| epoch  15 |   106/  269 batches | lr 0.003693 | 184.20 ms | loss 0.01149 | ppl     1.01\n",
            "| epoch  15 |   159/  269 batches | lr 0.003693 | 184.00 ms | loss 0.00977 | ppl     1.01\n",
            "| epoch  15 |   212/  269 batches | lr 0.003693 | 183.62 ms | loss 0.01157 | ppl     1.01\n",
            "| epoch  15 |   265/  269 batches | lr 0.003693 | 184.43 ms | loss 0.01077 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  15 | time: 54.63s | valid loss 0.27218 | valid ppl     1.31\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  16 |    53/  269 batches | lr 0.003619 | 185.89 ms | loss 0.02767 | ppl     1.03\n",
            "| epoch  16 |   106/  269 batches | lr 0.003619 | 182.88 ms | loss 0.00988 | ppl     1.01\n",
            "| epoch  16 |   159/  269 batches | lr 0.003619 | 183.79 ms | loss 0.00880 | ppl     1.01\n",
            "| epoch  16 |   212/  269 batches | lr 0.003619 | 185.06 ms | loss 0.00886 | ppl     1.01\n",
            "| epoch  16 |   265/  269 batches | lr 0.003619 | 184.56 ms | loss 0.00829 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  16 | time: 54.63s | valid loss 0.24559 | valid ppl     1.28\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  17 |    53/  269 batches | lr 0.003547 | 188.11 ms | loss 0.02498 | ppl     1.03\n",
            "| epoch  17 |   106/  269 batches | lr 0.003547 | 184.99 ms | loss 0.01123 | ppl     1.01\n",
            "| epoch  17 |   159/  269 batches | lr 0.003547 | 184.47 ms | loss 0.00834 | ppl     1.01\n",
            "| epoch  17 |   212/  269 batches | lr 0.003547 | 184.32 ms | loss 0.00874 | ppl     1.01\n",
            "| epoch  17 |   265/  269 batches | lr 0.003547 | 183.49 ms | loss 0.00874 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  17 | time: 54.77s | valid loss 0.23928 | valid ppl     1.27\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  18 |    53/  269 batches | lr 0.003476 | 186.94 ms | loss 0.03169 | ppl     1.03\n",
            "| epoch  18 |   106/  269 batches | lr 0.003476 | 184.30 ms | loss 0.01346 | ppl     1.01\n",
            "| epoch  18 |   159/  269 batches | lr 0.003476 | 183.08 ms | loss 0.00860 | ppl     1.01\n",
            "| epoch  18 |   212/  269 batches | lr 0.003476 | 181.72 ms | loss 0.00837 | ppl     1.01\n",
            "| epoch  18 |   265/  269 batches | lr 0.003476 | 181.05 ms | loss 0.00791 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  18 | time: 54.31s | valid loss 0.24889 | valid ppl     1.28\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  19 |    53/  269 batches | lr 0.003406 | 185.32 ms | loss 0.02973 | ppl     1.03\n",
            "| epoch  19 |   106/  269 batches | lr 0.003406 | 185.15 ms | loss 0.01294 | ppl     1.01\n",
            "| epoch  19 |   159/  269 batches | lr 0.003406 | 185.21 ms | loss 0.00899 | ppl     1.01\n",
            "| epoch  19 |   212/  269 batches | lr 0.003406 | 184.04 ms | loss 0.00788 | ppl     1.01\n",
            "| epoch  19 |   265/  269 batches | lr 0.003406 | 182.84 ms | loss 0.00709 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  19 | time: 54.64s | valid loss 0.25914 | valid ppl     1.30\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  20 |    53/  269 batches | lr 0.003338 | 188.66 ms | loss 0.02985 | ppl     1.03\n",
            "| epoch  20 |   106/  269 batches | lr 0.003338 | 185.16 ms | loss 0.01303 | ppl     1.01\n",
            "| epoch  20 |   159/  269 batches | lr 0.003338 | 183.64 ms | loss 0.00948 | ppl     1.01\n",
            "| epoch  20 |   212/  269 batches | lr 0.003338 | 185.39 ms | loss 0.00883 | ppl     1.01\n",
            "| epoch  20 |   265/  269 batches | lr 0.003338 | 185.76 ms | loss 0.00792 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  20 | time: 58.96s | valid loss 0.27379 | valid ppl     1.31\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  21 |    53/  269 batches | lr 0.003271 | 188.62 ms | loss 0.03297 | ppl     1.03\n",
            "| epoch  21 |   106/  269 batches | lr 0.003271 | 184.52 ms | loss 0.01010 | ppl     1.01\n",
            "| epoch  21 |   159/  269 batches | lr 0.003271 | 182.55 ms | loss 0.00915 | ppl     1.01\n",
            "| epoch  21 |   212/  269 batches | lr 0.003271 | 182.22 ms | loss 0.01035 | ppl     1.01\n",
            "| epoch  21 |   265/  269 batches | lr 0.003271 | 181.96 ms | loss 0.01023 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  21 | time: 54.45s | valid loss 0.28860 | valid ppl     1.33\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  22 |    53/  269 batches | lr 0.003206 | 185.04 ms | loss 0.03266 | ppl     1.03\n",
            "| epoch  22 |   106/  269 batches | lr 0.003206 | 180.97 ms | loss 0.01304 | ppl     1.01\n",
            "| epoch  22 |   159/  269 batches | lr 0.003206 | 181.21 ms | loss 0.00938 | ppl     1.01\n",
            "| epoch  22 |   212/  269 batches | lr 0.003206 | 180.79 ms | loss 0.00735 | ppl     1.01\n",
            "| epoch  22 |   265/  269 batches | lr 0.003206 | 181.37 ms | loss 0.00857 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  22 | time: 53.85s | valid loss 0.26363 | valid ppl     1.30\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  23 |    53/  269 batches | lr 0.003142 | 183.39 ms | loss 0.03058 | ppl     1.03\n",
            "| epoch  23 |   106/  269 batches | lr 0.003142 | 180.91 ms | loss 0.01283 | ppl     1.01\n",
            "| epoch  23 |   159/  269 batches | lr 0.003142 | 180.70 ms | loss 0.00975 | ppl     1.01\n",
            "| epoch  23 |   212/  269 batches | lr 0.003142 | 180.30 ms | loss 0.00804 | ppl     1.01\n",
            "| epoch  23 |   265/  269 batches | lr 0.003142 | 179.92 ms | loss 0.00948 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  23 | time: 53.62s | valid loss 0.26432 | valid ppl     1.30\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  24 |    53/  269 batches | lr 0.003079 | 182.27 ms | loss 0.03321 | ppl     1.03\n",
            "| epoch  24 |   106/  269 batches | lr 0.003079 | 180.12 ms | loss 0.01510 | ppl     1.02\n",
            "| epoch  24 |   159/  269 batches | lr 0.003079 | 178.88 ms | loss 0.01000 | ppl     1.01\n",
            "| epoch  24 |   212/  269 batches | lr 0.003079 | 180.14 ms | loss 0.00770 | ppl     1.01\n",
            "| epoch  24 |   265/  269 batches | lr 0.003079 | 182.18 ms | loss 0.00850 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  24 | time: 53.65s | valid loss 0.24848 | valid ppl     1.28\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  25 |    53/  269 batches | lr 0.003017 | 184.92 ms | loss 0.02974 | ppl     1.03\n",
            "| epoch  25 |   106/  269 batches | lr 0.003017 | 182.32 ms | loss 0.01878 | ppl     1.02\n",
            "| epoch  25 |   159/  269 batches | lr 0.003017 | 180.52 ms | loss 0.00873 | ppl     1.01\n",
            "| epoch  25 |   212/  269 batches | lr 0.003017 | 181.21 ms | loss 0.00792 | ppl     1.01\n",
            "| epoch  25 |   265/  269 batches | lr 0.003017 | 178.75 ms | loss 0.00926 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  25 | time: 53.78s | valid loss 0.24026 | valid ppl     1.27\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  26 |    53/  269 batches | lr 0.002957 | 183.20 ms | loss 0.02976 | ppl     1.03\n",
            "| epoch  26 |   106/  269 batches | lr 0.002957 | 181.28 ms | loss 0.01832 | ppl     1.02\n",
            "| epoch  26 |   159/  269 batches | lr 0.002957 | 178.50 ms | loss 0.00946 | ppl     1.01\n",
            "| epoch  26 |   212/  269 batches | lr 0.002957 | 179.18 ms | loss 0.00803 | ppl     1.01\n",
            "| epoch  26 |   265/  269 batches | lr 0.002957 | 179.02 ms | loss 0.00795 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  26 | time: 53.41s | valid loss 0.24114 | valid ppl     1.27\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  27 |    53/  269 batches | lr 0.002898 | 183.28 ms | loss 0.02948 | ppl     1.03\n",
            "| epoch  27 |   106/  269 batches | lr 0.002898 | 179.49 ms | loss 0.01843 | ppl     1.02\n",
            "| epoch  27 |   159/  269 batches | lr 0.002898 | 178.80 ms | loss 0.00927 | ppl     1.01\n",
            "| epoch  27 |   212/  269 batches | lr 0.002898 | 178.40 ms | loss 0.00815 | ppl     1.01\n",
            "| epoch  27 |   265/  269 batches | lr 0.002898 | 178.97 ms | loss 0.00797 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  27 | time: 53.27s | valid loss 0.25270 | valid ppl     1.29\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  28 |    53/  269 batches | lr 0.002840 | 181.88 ms | loss 0.02936 | ppl     1.03\n",
            "| epoch  28 |   106/  269 batches | lr 0.002840 | 176.50 ms | loss 0.01992 | ppl     1.02\n",
            "| epoch  28 |   159/  269 batches | lr 0.002840 | 176.51 ms | loss 0.01015 | ppl     1.01\n",
            "| epoch  28 |   212/  269 batches | lr 0.002840 | 177.33 ms | loss 0.00829 | ppl     1.01\n",
            "| epoch  28 |   265/  269 batches | lr 0.002840 | 176.92 ms | loss 0.00763 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  28 | time: 52.76s | valid loss 0.26262 | valid ppl     1.30\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  29 |    53/  269 batches | lr 0.002783 | 179.96 ms | loss 0.03085 | ppl     1.03\n",
            "| epoch  29 |   106/  269 batches | lr 0.002783 | 176.24 ms | loss 0.01172 | ppl     1.01\n",
            "| epoch  29 |   159/  269 batches | lr 0.002783 | 177.13 ms | loss 0.00978 | ppl     1.01\n",
            "| epoch  29 |   212/  269 batches | lr 0.002783 | 178.15 ms | loss 0.00874 | ppl     1.01\n",
            "| epoch  29 |   265/  269 batches | lr 0.002783 | 179.28 ms | loss 0.00889 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  29 | time: 52.93s | valid loss 0.27180 | valid ppl     1.31\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  30 |    53/  269 batches | lr 0.002727 | 185.45 ms | loss 0.03231 | ppl     1.03\n",
            "| epoch  30 |   106/  269 batches | lr 0.002727 | 181.58 ms | loss 0.01629 | ppl     1.02\n",
            "| epoch  30 |   159/  269 batches | lr 0.002727 | 181.23 ms | loss 0.01001 | ppl     1.01\n",
            "| epoch  30 |   212/  269 batches | lr 0.002727 | 180.39 ms | loss 0.00810 | ppl     1.01\n",
            "| epoch  30 |   265/  269 batches | lr 0.002727 | 178.29 ms | loss 0.00800 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  30 | time: 57.34s | valid loss 0.30917 | valid ppl     1.36\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  31 |    53/  269 batches | lr 0.002673 | 190.19 ms | loss 0.03438 | ppl     1.03\n",
            "| epoch  31 |   106/  269 batches | lr 0.002673 | 186.33 ms | loss 0.01243 | ppl     1.01\n",
            "| epoch  31 |   159/  269 batches | lr 0.002673 | 186.23 ms | loss 0.01107 | ppl     1.01\n",
            "| epoch  31 |   212/  269 batches | lr 0.002673 | 186.21 ms | loss 0.00810 | ppl     1.01\n",
            "| epoch  31 |   265/  269 batches | lr 0.002673 | 187.79 ms | loss 0.00796 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  31 | time: 55.38s | valid loss 0.27429 | valid ppl     1.32\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  32 |    53/  269 batches | lr 0.002619 | 195.61 ms | loss 0.03022 | ppl     1.03\n",
            "| epoch  32 |   106/  269 batches | lr 0.002619 | 193.42 ms | loss 0.01248 | ppl     1.01\n",
            "| epoch  32 |   159/  269 batches | lr 0.002619 | 191.93 ms | loss 0.01288 | ppl     1.01\n",
            "| epoch  32 |   212/  269 batches | lr 0.002619 | 193.35 ms | loss 0.00844 | ppl     1.01\n",
            "| epoch  32 |   265/  269 batches | lr 0.002619 | 192.07 ms | loss 0.00870 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  32 | time: 56.94s | valid loss 0.26530 | valid ppl     1.30\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  33 |    53/  269 batches | lr 0.002567 | 197.59 ms | loss 0.02778 | ppl     1.03\n",
            "| epoch  33 |   106/  269 batches | lr 0.002567 | 194.84 ms | loss 0.01022 | ppl     1.01\n",
            "| epoch  33 |   159/  269 batches | lr 0.002567 | 193.43 ms | loss 0.01085 | ppl     1.01\n",
            "| epoch  33 |   212/  269 batches | lr 0.002567 | 193.78 ms | loss 0.00861 | ppl     1.01\n",
            "| epoch  33 |   265/  269 batches | lr 0.002567 | 194.55 ms | loss 0.00775 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  33 | time: 57.37s | valid loss 0.28211 | valid ppl     1.33\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  34 |    53/  269 batches | lr 0.002516 | 196.70 ms | loss 0.03039 | ppl     1.03\n",
            "| epoch  34 |   106/  269 batches | lr 0.002516 | 194.30 ms | loss 0.00999 | ppl     1.01\n",
            "| epoch  34 |   159/  269 batches | lr 0.002516 | 192.71 ms | loss 0.01051 | ppl     1.01\n",
            "| epoch  34 |   212/  269 batches | lr 0.002516 | 193.18 ms | loss 0.00882 | ppl     1.01\n",
            "| epoch  34 |   265/  269 batches | lr 0.002516 | 194.82 ms | loss 0.00779 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  34 | time: 57.24s | valid loss 0.27584 | valid ppl     1.32\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  35 |    53/  269 batches | lr 0.002465 | 197.93 ms | loss 0.02682 | ppl     1.03\n",
            "| epoch  35 |   106/  269 batches | lr 0.002465 | 195.77 ms | loss 0.00736 | ppl     1.01\n",
            "| epoch  35 |   159/  269 batches | lr 0.002465 | 194.85 ms | loss 0.00876 | ppl     1.01\n",
            "| epoch  35 |   212/  269 batches | lr 0.002465 | 193.56 ms | loss 0.00870 | ppl     1.01\n",
            "| epoch  35 |   265/  269 batches | lr 0.002465 | 195.30 ms | loss 0.00865 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  35 | time: 57.55s | valid loss 0.28332 | valid ppl     1.33\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  36 |    53/  269 batches | lr 0.002416 | 198.93 ms | loss 0.02860 | ppl     1.03\n",
            "| epoch  36 |   106/  269 batches | lr 0.002416 | 194.00 ms | loss 0.01035 | ppl     1.01\n",
            "| epoch  36 |   159/  269 batches | lr 0.002416 | 193.06 ms | loss 0.00931 | ppl     1.01\n",
            "| epoch  36 |   212/  269 batches | lr 0.002416 | 193.74 ms | loss 0.00869 | ppl     1.01\n",
            "| epoch  36 |   265/  269 batches | lr 0.002416 | 194.78 ms | loss 0.00838 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  36 | time: 57.43s | valid loss 0.29497 | valid ppl     1.34\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  37 |    53/  269 batches | lr 0.002368 | 198.06 ms | loss 0.02578 | ppl     1.03\n",
            "| epoch  37 |   106/  269 batches | lr 0.002368 | 194.56 ms | loss 0.00928 | ppl     1.01\n",
            "| epoch  37 |   159/  269 batches | lr 0.002368 | 195.44 ms | loss 0.01080 | ppl     1.01\n",
            "| epoch  37 |   212/  269 batches | lr 0.002368 | 195.89 ms | loss 0.00796 | ppl     1.01\n",
            "| epoch  37 |   265/  269 batches | lr 0.002368 | 195.83 ms | loss 0.00747 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  37 | time: 57.76s | valid loss 0.29076 | valid ppl     1.34\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  38 |    53/  269 batches | lr 0.002320 | 198.80 ms | loss 0.02832 | ppl     1.03\n",
            "| epoch  38 |   106/  269 batches | lr 0.002320 | 196.36 ms | loss 0.00973 | ppl     1.01\n",
            "| epoch  38 |   159/  269 batches | lr 0.002320 | 195.47 ms | loss 0.00994 | ppl     1.01\n",
            "| epoch  38 |   212/  269 batches | lr 0.002320 | 194.67 ms | loss 0.00809 | ppl     1.01\n",
            "| epoch  38 |   265/  269 batches | lr 0.002320 | 194.65 ms | loss 0.00731 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  38 | time: 57.70s | valid loss 0.29448 | valid ppl     1.34\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  39 |    53/  269 batches | lr 0.002274 | 198.36 ms | loss 0.02879 | ppl     1.03\n",
            "| epoch  39 |   106/  269 batches | lr 0.002274 | 195.20 ms | loss 0.00845 | ppl     1.01\n",
            "| epoch  39 |   159/  269 batches | lr 0.002274 | 195.42 ms | loss 0.01015 | ppl     1.01\n",
            "| epoch  39 |   212/  269 batches | lr 0.002274 | 194.51 ms | loss 0.00840 | ppl     1.01\n",
            "| epoch  39 |   265/  269 batches | lr 0.002274 | 194.60 ms | loss 0.00783 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  39 | time: 57.64s | valid loss 0.31647 | valid ppl     1.37\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  40 |    53/  269 batches | lr 0.002229 | 200.35 ms | loss 0.03002 | ppl     1.03\n",
            "| epoch  40 |   106/  269 batches | lr 0.002229 | 196.82 ms | loss 0.00968 | ppl     1.01\n",
            "| epoch  40 |   159/  269 batches | lr 0.002229 | 196.13 ms | loss 0.01073 | ppl     1.01\n",
            "| epoch  40 |   212/  269 batches | lr 0.002229 | 194.49 ms | loss 0.00767 | ppl     1.01\n",
            "| epoch  40 |   265/  269 batches | lr 0.002229 | 193.95 ms | loss 0.00737 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  40 | time: 61.47s | valid loss 0.34424 | valid ppl     1.41\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  41 |    53/  269 batches | lr 0.002184 | 185.49 ms | loss 0.03097 | ppl     1.03\n",
            "| epoch  41 |   106/  269 batches | lr 0.002184 | 181.68 ms | loss 0.00868 | ppl     1.01\n",
            "| epoch  41 |   159/  269 batches | lr 0.002184 | 182.20 ms | loss 0.01052 | ppl     1.01\n",
            "| epoch  41 |   212/  269 batches | lr 0.002184 | 182.06 ms | loss 0.00724 | ppl     1.01\n",
            "| epoch  41 |   265/  269 batches | lr 0.002184 | 182.44 ms | loss 0.00783 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  41 | time: 54.17s | valid loss 0.30456 | valid ppl     1.36\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  42 |    53/  269 batches | lr 0.002140 | 186.55 ms | loss 0.03419 | ppl     1.03\n",
            "| epoch  42 |   106/  269 batches | lr 0.002140 | 182.25 ms | loss 0.01155 | ppl     1.01\n",
            "| epoch  42 |   159/  269 batches | lr 0.002140 | 180.38 ms | loss 0.00996 | ppl     1.01\n",
            "| epoch  42 |   212/  269 batches | lr 0.002140 | 180.74 ms | loss 0.00762 | ppl     1.01\n",
            "| epoch  42 |   265/  269 batches | lr 0.002140 | 182.29 ms | loss 0.00833 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  42 | time: 54.07s | valid loss 0.30600 | valid ppl     1.36\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  43 |    53/  269 batches | lr 0.002097 | 185.47 ms | loss 0.03398 | ppl     1.03\n",
            "| epoch  43 |   106/  269 batches | lr 0.002097 | 181.99 ms | loss 0.01708 | ppl     1.02\n",
            "| epoch  43 |   159/  269 batches | lr 0.002097 | 181.03 ms | loss 0.01127 | ppl     1.01\n",
            "| epoch  43 |   212/  269 batches | lr 0.002097 | 180.85 ms | loss 0.00737 | ppl     1.01\n",
            "| epoch  43 |   265/  269 batches | lr 0.002097 | 180.56 ms | loss 0.00871 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  43 | time: 53.94s | valid loss 0.27858 | valid ppl     1.32\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  44 |    53/  269 batches | lr 0.002055 | 185.38 ms | loss 0.03004 | ppl     1.03\n",
            "| epoch  44 |   106/  269 batches | lr 0.002055 | 181.06 ms | loss 0.01775 | ppl     1.02\n",
            "| epoch  44 |   159/  269 batches | lr 0.002055 | 182.78 ms | loss 0.01400 | ppl     1.01\n",
            "| epoch  44 |   212/  269 batches | lr 0.002055 | 181.86 ms | loss 0.00819 | ppl     1.01\n",
            "| epoch  44 |   265/  269 batches | lr 0.002055 | 182.31 ms | loss 0.00871 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  44 | time: 54.15s | valid loss 0.26109 | valid ppl     1.30\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  45 |    53/  269 batches | lr 0.002014 | 184.13 ms | loss 0.02712 | ppl     1.03\n",
            "| epoch  45 |   106/  269 batches | lr 0.002014 | 183.61 ms | loss 0.01584 | ppl     1.02\n",
            "| epoch  45 |   159/  269 batches | lr 0.002014 | 183.95 ms | loss 0.01696 | ppl     1.02\n",
            "| epoch  45 |   212/  269 batches | lr 0.002014 | 184.22 ms | loss 0.00840 | ppl     1.01\n",
            "| epoch  45 |   265/  269 batches | lr 0.002014 | 184.27 ms | loss 0.00853 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  45 | time: 54.51s | valid loss 0.24513 | valid ppl     1.28\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  46 |    53/  269 batches | lr 0.001974 | 187.33 ms | loss 0.02975 | ppl     1.03\n",
            "| epoch  46 |   106/  269 batches | lr 0.001974 | 182.56 ms | loss 0.02445 | ppl     1.02\n",
            "| epoch  46 |   159/  269 batches | lr 0.001974 | 182.38 ms | loss 0.03192 | ppl     1.03\n",
            "| epoch  46 |   212/  269 batches | lr 0.001974 | 184.57 ms | loss 0.01341 | ppl     1.01\n",
            "| epoch  46 |   265/  269 batches | lr 0.001974 | 184.42 ms | loss 0.01191 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  46 | time: 54.54s | valid loss 0.20839 | valid ppl     1.23\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  47 |    53/  269 batches | lr 0.001935 | 187.12 ms | loss 0.03318 | ppl     1.03\n",
            "| epoch  47 |   106/  269 batches | lr 0.001935 | 184.17 ms | loss 0.03750 | ppl     1.04\n",
            "| epoch  47 |   159/  269 batches | lr 0.001935 | 182.12 ms | loss 0.03523 | ppl     1.04\n",
            "| epoch  47 |   212/  269 batches | lr 0.001935 | 181.69 ms | loss 0.01295 | ppl     1.01\n",
            "| epoch  47 |   265/  269 batches | lr 0.001935 | 181.18 ms | loss 0.01220 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  47 | time: 54.29s | valid loss 0.20994 | valid ppl     1.23\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  48 |    53/  269 batches | lr 0.001896 | 183.61 ms | loss 0.03619 | ppl     1.04\n",
            "| epoch  48 |   106/  269 batches | lr 0.001896 | 180.95 ms | loss 0.04008 | ppl     1.04\n",
            "| epoch  48 |   159/  269 batches | lr 0.001896 | 181.11 ms | loss 0.03664 | ppl     1.04\n",
            "| epoch  48 |   212/  269 batches | lr 0.001896 | 181.67 ms | loss 0.01338 | ppl     1.01\n",
            "| epoch  48 |   265/  269 batches | lr 0.001896 | 181.87 ms | loss 0.01392 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  48 | time: 53.86s | valid loss 0.20098 | valid ppl     1.22\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  49 |    53/  269 batches | lr 0.001858 | 185.17 ms | loss 0.03551 | ppl     1.04\n",
            "| epoch  49 |   106/  269 batches | lr 0.001858 | 180.22 ms | loss 0.03641 | ppl     1.04\n",
            "| epoch  49 |   159/  269 batches | lr 0.001858 | 180.53 ms | loss 0.03015 | ppl     1.03\n",
            "| epoch  49 |   212/  269 batches | lr 0.001858 | 182.46 ms | loss 0.01312 | ppl     1.01\n",
            "| epoch  49 |   265/  269 batches | lr 0.001858 | 181.39 ms | loss 0.01344 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  49 | time: 53.94s | valid loss 0.18913 | valid ppl     1.21\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  50 |    53/  269 batches | lr 0.001821 | 184.10 ms | loss 0.03628 | ppl     1.04\n",
            "| epoch  50 |   106/  269 batches | lr 0.001821 | 181.04 ms | loss 0.04997 | ppl     1.05\n",
            "| epoch  50 |   159/  269 batches | lr 0.001821 | 181.65 ms | loss 0.02934 | ppl     1.03\n",
            "| epoch  50 |   212/  269 batches | lr 0.001821 | 181.04 ms | loss 0.01284 | ppl     1.01\n",
            "| epoch  50 |   265/  269 batches | lr 0.001821 | 181.33 ms | loss 0.01385 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  50 | time: 57.43s | valid loss 0.17537 | valid ppl     1.19\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  51 |    53/  269 batches | lr 0.001784 | 190.64 ms | loss 0.03317 | ppl     1.03\n",
            "| epoch  51 |   106/  269 batches | lr 0.001784 | 188.32 ms | loss 0.04995 | ppl     1.05\n",
            "| epoch  51 |   159/  269 batches | lr 0.001784 | 188.53 ms | loss 0.03722 | ppl     1.04\n",
            "| epoch  51 |   212/  269 batches | lr 0.001784 | 189.39 ms | loss 0.02109 | ppl     1.02\n",
            "| epoch  51 |   265/  269 batches | lr 0.001784 | 189.90 ms | loss 0.01663 | ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  51 | time: 56.01s | valid loss 0.16662 | valid ppl     1.18\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  52 |    53/  269 batches | lr 0.001749 | 191.25 ms | loss 0.03092 | ppl     1.03\n",
            "| epoch  52 |   106/  269 batches | lr 0.001749 | 189.10 ms | loss 0.03471 | ppl     1.04\n",
            "| epoch  52 |   159/  269 batches | lr 0.001749 | 187.23 ms | loss 0.02988 | ppl     1.03\n",
            "| epoch  52 |   212/  269 batches | lr 0.001749 | 188.03 ms | loss 0.01785 | ppl     1.02\n",
            "| epoch  52 |   265/  269 batches | lr 0.001749 | 188.52 ms | loss 0.01727 | ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  52 | time: 55.77s | valid loss 0.13001 | valid ppl     1.14\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  53 |    53/  269 batches | lr 0.001714 | 191.37 ms | loss 0.02909 | ppl     1.03\n",
            "| epoch  53 |   106/  269 batches | lr 0.001714 | 188.91 ms | loss 0.04084 | ppl     1.04\n",
            "| epoch  53 |   159/  269 batches | lr 0.001714 | 188.28 ms | loss 0.03905 | ppl     1.04\n",
            "| epoch  53 |   212/  269 batches | lr 0.001714 | 189.09 ms | loss 0.02057 | ppl     1.02\n",
            "| epoch  53 |   265/  269 batches | lr 0.001714 | 186.90 ms | loss 0.01812 | ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  53 | time: 55.82s | valid loss 0.11403 | valid ppl     1.12\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  54 |    53/  269 batches | lr 0.001679 | 192.55 ms | loss 0.02801 | ppl     1.03\n",
            "| epoch  54 |   106/  269 batches | lr 0.001679 | 188.78 ms | loss 0.02435 | ppl     1.02\n",
            "| epoch  54 |   159/  269 batches | lr 0.001679 | 187.98 ms | loss 0.02700 | ppl     1.03\n",
            "| epoch  54 |   212/  269 batches | lr 0.001679 | 188.46 ms | loss 0.01775 | ppl     1.02\n",
            "| epoch  54 |   265/  269 batches | lr 0.001679 | 189.19 ms | loss 0.01683 | ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  54 | time: 55.97s | valid loss 0.06588 | valid ppl     1.07\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  55 |    53/  269 batches | lr 0.001646 | 191.98 ms | loss 0.02098 | ppl     1.02\n",
            "| epoch  55 |   106/  269 batches | lr 0.001646 | 189.36 ms | loss 0.02299 | ppl     1.02\n",
            "| epoch  55 |   159/  269 batches | lr 0.001646 | 188.77 ms | loss 0.02940 | ppl     1.03\n",
            "| epoch  55 |   212/  269 batches | lr 0.001646 | 188.10 ms | loss 0.02061 | ppl     1.02\n",
            "| epoch  55 |   265/  269 batches | lr 0.001646 | 189.17 ms | loss 0.01454 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  55 | time: 55.93s | valid loss 0.05116 | valid ppl     1.05\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  56 |    53/  269 batches | lr 0.001613 | 192.24 ms | loss 0.01978 | ppl     1.02\n",
            "| epoch  56 |   106/  269 batches | lr 0.001613 | 190.55 ms | loss 0.01515 | ppl     1.02\n",
            "| epoch  56 |   159/  269 batches | lr 0.001613 | 191.50 ms | loss 0.02492 | ppl     1.03\n",
            "| epoch  56 |   212/  269 batches | lr 0.001613 | 190.71 ms | loss 0.01855 | ppl     1.02\n",
            "| epoch  56 |   265/  269 batches | lr 0.001613 | 189.54 ms | loss 0.01589 | ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  56 | time: 56.28s | valid loss 0.04463 | valid ppl     1.05\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  57 |    53/  269 batches | lr 0.001581 | 190.57 ms | loss 0.01926 | ppl     1.02\n",
            "| epoch  57 |   106/  269 batches | lr 0.001581 | 189.14 ms | loss 0.01547 | ppl     1.02\n",
            "| epoch  57 |   159/  269 batches | lr 0.001581 | 187.92 ms | loss 0.02188 | ppl     1.02\n",
            "| epoch  57 |   212/  269 batches | lr 0.001581 | 188.86 ms | loss 0.01694 | ppl     1.02\n",
            "| epoch  57 |   265/  269 batches | lr 0.001581 | 188.66 ms | loss 0.01478 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  57 | time: 55.82s | valid loss 0.03922 | valid ppl     1.04\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  58 |    53/  269 batches | lr 0.001549 | 191.37 ms | loss 0.01889 | ppl     1.02\n",
            "| epoch  58 |   106/  269 batches | lr 0.001549 | 189.63 ms | loss 0.01497 | ppl     1.02\n",
            "| epoch  58 |   159/  269 batches | lr 0.001549 | 188.24 ms | loss 0.01795 | ppl     1.02\n",
            "| epoch  58 |   212/  269 batches | lr 0.001549 | 188.39 ms | loss 0.01692 | ppl     1.02\n",
            "| epoch  58 |   265/  269 batches | lr 0.001549 | 186.99 ms | loss 0.01302 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  58 | time: 55.73s | valid loss 0.03354 | valid ppl     1.03\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  59 |    53/  269 batches | lr 0.001518 | 189.08 ms | loss 0.01824 | ppl     1.02\n",
            "| epoch  59 |   106/  269 batches | lr 0.001518 | 187.99 ms | loss 0.01450 | ppl     1.01\n",
            "| epoch  59 |   159/  269 batches | lr 0.001518 | 188.26 ms | loss 0.01513 | ppl     1.02\n",
            "| epoch  59 |   212/  269 batches | lr 0.001518 | 189.69 ms | loss 0.01719 | ppl     1.02\n",
            "| epoch  59 |   265/  269 batches | lr 0.001518 | 190.10 ms | loss 0.01329 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  59 | time: 55.84s | valid loss 0.02887 | valid ppl     1.03\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  60 |    53/  269 batches | lr 0.001488 | 191.57 ms | loss 0.01700 | ppl     1.02\n",
            "| epoch  60 |   106/  269 batches | lr 0.001488 | 188.06 ms | loss 0.01333 | ppl     1.01\n",
            "| epoch  60 |   159/  269 batches | lr 0.001488 | 188.10 ms | loss 0.01577 | ppl     1.02\n",
            "| epoch  60 |   212/  269 batches | lr 0.001488 | 189.36 ms | loss 0.01542 | ppl     1.02\n",
            "| epoch  60 |   265/  269 batches | lr 0.001488 | 189.36 ms | loss 0.01244 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  60 | time: 59.42s | valid loss 0.03141 | valid ppl     1.03\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  61 |    53/  269 batches | lr 0.001458 | 191.51 ms | loss 0.01850 | ppl     1.02\n",
            "| epoch  61 |   106/  269 batches | lr 0.001458 | 189.49 ms | loss 0.01382 | ppl     1.01\n",
            "| epoch  61 |   159/  269 batches | lr 0.001458 | 188.69 ms | loss 0.01397 | ppl     1.01\n",
            "| epoch  61 |   212/  269 batches | lr 0.001458 | 188.66 ms | loss 0.01560 | ppl     1.02\n",
            "| epoch  61 |   265/  269 batches | lr 0.001458 | 190.29 ms | loss 0.01145 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  61 | time: 56.03s | valid loss 0.02794 | valid ppl     1.03\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  62 |    53/  269 batches | lr 0.001429 | 194.05 ms | loss 0.01728 | ppl     1.02\n",
            "| epoch  62 |   106/  269 batches | lr 0.001429 | 190.72 ms | loss 0.01427 | ppl     1.01\n",
            "| epoch  62 |   159/  269 batches | lr 0.001429 | 188.96 ms | loss 0.01395 | ppl     1.01\n",
            "| epoch  62 |   212/  269 batches | lr 0.001429 | 190.06 ms | loss 0.01595 | ppl     1.02\n",
            "| epoch  62 |   265/  269 batches | lr 0.001429 | 190.31 ms | loss 0.01119 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  62 | time: 56.37s | valid loss 0.02880 | valid ppl     1.03\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  63 |    53/  269 batches | lr 0.001400 | 194.26 ms | loss 0.01743 | ppl     1.02\n",
            "| epoch  63 |   106/  269 batches | lr 0.001400 | 191.23 ms | loss 0.01395 | ppl     1.01\n",
            "| epoch  63 |   159/  269 batches | lr 0.001400 | 191.25 ms | loss 0.01448 | ppl     1.01\n",
            "| epoch  63 |   212/  269 batches | lr 0.001400 | 191.29 ms | loss 0.01580 | ppl     1.02\n",
            "| epoch  63 |   265/  269 batches | lr 0.001400 | 188.60 ms | loss 0.01188 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  63 | time: 56.43s | valid loss 0.03073 | valid ppl     1.03\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  64 |    53/  269 batches | lr 0.001372 | 193.24 ms | loss 0.01562 | ppl     1.02\n",
            "| epoch  64 |   106/  269 batches | lr 0.001372 | 189.07 ms | loss 0.01385 | ppl     1.01\n",
            "| epoch  64 |   159/  269 batches | lr 0.001372 | 189.97 ms | loss 0.01452 | ppl     1.01\n",
            "| epoch  64 |   212/  269 batches | lr 0.001372 | 191.00 ms | loss 0.01530 | ppl     1.02\n",
            "| epoch  64 |   265/  269 batches | lr 0.001372 | 190.15 ms | loss 0.01121 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  64 | time: 56.30s | valid loss 0.03925 | valid ppl     1.04\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  65 |    53/  269 batches | lr 0.001345 | 193.35 ms | loss 0.01480 | ppl     1.01\n",
            "| epoch  65 |   106/  269 batches | lr 0.001345 | 191.23 ms | loss 0.01328 | ppl     1.01\n",
            "| epoch  65 |   159/  269 batches | lr 0.001345 | 189.12 ms | loss 0.01458 | ppl     1.01\n",
            "| epoch  65 |   212/  269 batches | lr 0.001345 | 188.14 ms | loss 0.01486 | ppl     1.01\n",
            "| epoch  65 |   265/  269 batches | lr 0.001345 | 189.69 ms | loss 0.01047 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  65 | time: 56.18s | valid loss 0.03182 | valid ppl     1.03\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  66 |    53/  269 batches | lr 0.001318 | 192.92 ms | loss 0.01575 | ppl     1.02\n",
            "| epoch  66 |   106/  269 batches | lr 0.001318 | 189.75 ms | loss 0.01260 | ppl     1.01\n",
            "| epoch  66 |   159/  269 batches | lr 0.001318 | 189.65 ms | loss 0.01480 | ppl     1.01\n",
            "| epoch  66 |   212/  269 batches | lr 0.001318 | 188.93 ms | loss 0.01392 | ppl     1.01\n",
            "| epoch  66 |   265/  269 batches | lr 0.001318 | 188.35 ms | loss 0.01039 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  66 | time: 56.07s | valid loss 0.02943 | valid ppl     1.03\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  67 |    53/  269 batches | lr 0.001292 | 190.83 ms | loss 0.01578 | ppl     1.02\n",
            "| epoch  67 |   106/  269 batches | lr 0.001292 | 189.97 ms | loss 0.01188 | ppl     1.01\n",
            "| epoch  67 |   159/  269 batches | lr 0.001292 | 187.26 ms | loss 0.01374 | ppl     1.01\n",
            "| epoch  67 |   212/  269 batches | lr 0.001292 | 189.54 ms | loss 0.01410 | ppl     1.01\n",
            "| epoch  67 |   265/  269 batches | lr 0.001292 | 188.00 ms | loss 0.01087 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  67 | time: 55.87s | valid loss 0.02934 | valid ppl     1.03\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  68 |    53/  269 batches | lr 0.001266 | 192.80 ms | loss 0.01508 | ppl     1.02\n",
            "| epoch  68 |   106/  269 batches | lr 0.001266 | 189.39 ms | loss 0.01123 | ppl     1.01\n",
            "| epoch  68 |   159/  269 batches | lr 0.001266 | 189.24 ms | loss 0.01397 | ppl     1.01\n",
            "| epoch  68 |   212/  269 batches | lr 0.001266 | 189.78 ms | loss 0.01474 | ppl     1.01\n",
            "| epoch  68 |   265/  269 batches | lr 0.001266 | 188.20 ms | loss 0.01144 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  68 | time: 56.05s | valid loss 0.02713 | valid ppl     1.03\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  69 |    53/  269 batches | lr 0.001240 | 191.45 ms | loss 0.01761 | ppl     1.02\n",
            "| epoch  69 |   106/  269 batches | lr 0.001240 | 188.52 ms | loss 0.01110 | ppl     1.01\n",
            "| epoch  69 |   159/  269 batches | lr 0.001240 | 188.41 ms | loss 0.01464 | ppl     1.01\n",
            "| epoch  69 |   212/  269 batches | lr 0.001240 | 188.27 ms | loss 0.01519 | ppl     1.02\n",
            "| epoch  69 |   265/  269 batches | lr 0.001240 | 186.97 ms | loss 0.01176 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  69 | time: 55.79s | valid loss 0.02716 | valid ppl     1.03\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  70 |    53/  269 batches | lr 0.001216 | 192.39 ms | loss 0.01704 | ppl     1.02\n",
            "| epoch  70 |   106/  269 batches | lr 0.001216 | 188.86 ms | loss 0.01144 | ppl     1.01\n",
            "| epoch  70 |   159/  269 batches | lr 0.001216 | 188.26 ms | loss 0.01503 | ppl     1.02\n",
            "| epoch  70 |   212/  269 batches | lr 0.001216 | 187.70 ms | loss 0.01404 | ppl     1.01\n",
            "| epoch  70 |   265/  269 batches | lr 0.001216 | 189.05 ms | loss 0.01199 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  70 | time: 59.25s | valid loss 0.02220 | valid ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  71 |    53/  269 batches | lr 0.001191 | 210.17 ms | loss 0.01636 | ppl     1.02\n",
            "| epoch  71 |   106/  269 batches | lr 0.001191 | 207.25 ms | loss 0.01081 | ppl     1.01\n",
            "| epoch  71 |   159/  269 batches | lr 0.001191 | 205.15 ms | loss 0.01403 | ppl     1.01\n",
            "| epoch  71 |   212/  269 batches | lr 0.001191 | 206.44 ms | loss 0.01341 | ppl     1.01\n",
            "| epoch  71 |   265/  269 batches | lr 0.001191 | 206.54 ms | loss 0.01154 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  71 | time: 60.65s | valid loss 0.01952 | valid ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  72 |    53/  269 batches | lr 0.001167 | 207.47 ms | loss 0.01647 | ppl     1.02\n",
            "| epoch  72 |   106/  269 batches | lr 0.001167 | 204.76 ms | loss 0.01163 | ppl     1.01\n",
            "| epoch  72 |   159/  269 batches | lr 0.001167 | 203.53 ms | loss 0.01307 | ppl     1.01\n",
            "| epoch  72 |   212/  269 batches | lr 0.001167 | 203.32 ms | loss 0.01367 | ppl     1.01\n",
            "| epoch  72 |   265/  269 batches | lr 0.001167 | 205.00 ms | loss 0.01221 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  72 | time: 60.02s | valid loss 0.01885 | valid ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  73 |    53/  269 batches | lr 0.001144 | 208.29 ms | loss 0.01533 | ppl     1.02\n",
            "| epoch  73 |   106/  269 batches | lr 0.001144 | 205.87 ms | loss 0.01071 | ppl     1.01\n",
            "| epoch  73 |   159/  269 batches | lr 0.001144 | 206.65 ms | loss 0.01213 | ppl     1.01\n",
            "| epoch  73 |   212/  269 batches | lr 0.001144 | 208.25 ms | loss 0.01365 | ppl     1.01\n",
            "| epoch  73 |   265/  269 batches | lr 0.001144 | 208.17 ms | loss 0.01187 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  73 | time: 60.77s | valid loss 0.01756 | valid ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  74 |    53/  269 batches | lr 0.001121 | 212.30 ms | loss 0.01497 | ppl     1.02\n",
            "| epoch  74 |   106/  269 batches | lr 0.001121 | 208.12 ms | loss 0.01101 | ppl     1.01\n",
            "| epoch  74 |   159/  269 batches | lr 0.001121 | 207.71 ms | loss 0.01282 | ppl     1.01\n",
            "| epoch  74 |   212/  269 batches | lr 0.001121 | 209.44 ms | loss 0.01261 | ppl     1.01\n",
            "| epoch  74 |   265/  269 batches | lr 0.001121 | 208.08 ms | loss 0.01079 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  74 | time: 61.22s | valid loss 0.01817 | valid ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  75 |    53/  269 batches | lr 0.001099 | 211.28 ms | loss 0.01516 | ppl     1.02\n",
            "| epoch  75 |   106/  269 batches | lr 0.001099 | 206.55 ms | loss 0.01064 | ppl     1.01\n",
            "| epoch  75 |   159/  269 batches | lr 0.001099 | 206.97 ms | loss 0.01154 | ppl     1.01\n",
            "| epoch  75 |   212/  269 batches | lr 0.001099 | 207.02 ms | loss 0.01237 | ppl     1.01\n",
            "| epoch  75 |   265/  269 batches | lr 0.001099 | 207.44 ms | loss 0.01061 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  75 | time: 60.90s | valid loss 0.02186 | valid ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  76 |    53/  269 batches | lr 0.001077 | 211.11 ms | loss 0.01457 | ppl     1.01\n",
            "| epoch  76 |   106/  269 batches | lr 0.001077 | 206.89 ms | loss 0.01034 | ppl     1.01\n",
            "| epoch  76 |   159/  269 batches | lr 0.001077 | 205.35 ms | loss 0.01179 | ppl     1.01\n",
            "| epoch  76 |   212/  269 batches | lr 0.001077 | 208.23 ms | loss 0.01221 | ppl     1.01\n",
            "| epoch  76 |   265/  269 batches | lr 0.001077 | 206.84 ms | loss 0.00993 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  76 | time: 60.84s | valid loss 0.01839 | valid ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  77 |    53/  269 batches | lr 0.001055 | 212.16 ms | loss 0.01388 | ppl     1.01\n",
            "| epoch  77 |   106/  269 batches | lr 0.001055 | 208.49 ms | loss 0.01070 | ppl     1.01\n",
            "| epoch  77 |   159/  269 batches | lr 0.001055 | 207.94 ms | loss 0.01203 | ppl     1.01\n",
            "| epoch  77 |   212/  269 batches | lr 0.001055 | 208.11 ms | loss 0.01260 | ppl     1.01\n",
            "| epoch  77 |   265/  269 batches | lr 0.001055 | 207.86 ms | loss 0.01055 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  77 | time: 61.17s | valid loss 0.01595 | valid ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  78 |    53/  269 batches | lr 0.001034 | 211.43 ms | loss 0.01334 | ppl     1.01\n",
            "| epoch  78 |   106/  269 batches | lr 0.001034 | 207.80 ms | loss 0.01072 | ppl     1.01\n",
            "| epoch  78 |   159/  269 batches | lr 0.001034 | 207.27 ms | loss 0.01109 | ppl     1.01\n",
            "| epoch  78 |   212/  269 batches | lr 0.001034 | 207.24 ms | loss 0.01191 | ppl     1.01\n",
            "| epoch  78 |   265/  269 batches | lr 0.001034 | 205.42 ms | loss 0.01114 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  78 | time: 60.89s | valid loss 0.01492 | valid ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  79 |    53/  269 batches | lr 0.001014 | 210.25 ms | loss 0.01373 | ppl     1.01\n",
            "| epoch  79 |   106/  269 batches | lr 0.001014 | 206.04 ms | loss 0.01013 | ppl     1.01\n",
            "| epoch  79 |   159/  269 batches | lr 0.001014 | 205.86 ms | loss 0.01056 | ppl     1.01\n",
            "| epoch  79 |   212/  269 batches | lr 0.001014 | 205.56 ms | loss 0.01226 | ppl     1.01\n",
            "| epoch  79 |   265/  269 batches | lr 0.001014 | 206.41 ms | loss 0.01086 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  79 | time: 60.59s | valid loss 0.01424 | valid ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  80 |    53/  269 batches | lr 0.000993 | 210.36 ms | loss 0.01279 | ppl     1.01\n",
            "| epoch  80 |   106/  269 batches | lr 0.000993 | 205.50 ms | loss 0.01007 | ppl     1.01\n",
            "| epoch  80 |   159/  269 batches | lr 0.000993 | 205.59 ms | loss 0.01026 | ppl     1.01\n",
            "| epoch  80 |   212/  269 batches | lr 0.000993 | 206.25 ms | loss 0.01122 | ppl     1.01\n",
            "| epoch  80 |   265/  269 batches | lr 0.000993 | 207.25 ms | loss 0.01066 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  80 | time: 64.27s | valid loss 0.01336 | valid ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  81 |    53/  269 batches | lr 0.000973 | 227.04 ms | loss 0.01321 | ppl     1.01\n",
            "| epoch  81 |   106/  269 batches | lr 0.000973 | 221.49 ms | loss 0.00999 | ppl     1.01\n",
            "| epoch  81 |   159/  269 batches | lr 0.000973 | 217.87 ms | loss 0.01150 | ppl     1.01\n",
            "| epoch  81 |   212/  269 batches | lr 0.000973 | 217.81 ms | loss 0.01090 | ppl     1.01\n",
            "| epoch  81 |   265/  269 batches | lr 0.000973 | 219.46 ms | loss 0.00966 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  81 | time: 64.31s | valid loss 0.01553 | valid ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  82 |    53/  269 batches | lr 0.000954 | 223.94 ms | loss 0.01297 | ppl     1.01\n",
            "| epoch  82 |   106/  269 batches | lr 0.000954 | 218.85 ms | loss 0.00981 | ppl     1.01\n",
            "| epoch  82 |   159/  269 batches | lr 0.000954 | 219.10 ms | loss 0.01040 | ppl     1.01\n",
            "| epoch  82 |   212/  269 batches | lr 0.000954 | 220.52 ms | loss 0.01080 | ppl     1.01\n",
            "| epoch  82 |   265/  269 batches | lr 0.000954 | 220.43 ms | loss 0.00970 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  82 | time: 64.33s | valid loss 0.01658 | valid ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  83 |    53/  269 batches | lr 0.000935 | 225.76 ms | loss 0.01280 | ppl     1.01\n",
            "| epoch  83 |   106/  269 batches | lr 0.000935 | 221.18 ms | loss 0.00968 | ppl     1.01\n",
            "| epoch  83 |   159/  269 batches | lr 0.000935 | 219.59 ms | loss 0.01016 | ppl     1.01\n",
            "| epoch  83 |   212/  269 batches | lr 0.000935 | 220.23 ms | loss 0.01071 | ppl     1.01\n",
            "| epoch  83 |   265/  269 batches | lr 0.000935 | 221.76 ms | loss 0.00961 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  83 | time: 64.61s | valid loss 0.01631 | valid ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  84 |    53/  269 batches | lr 0.000916 | 225.16 ms | loss 0.01191 | ppl     1.01\n",
            "| epoch  84 |   106/  269 batches | lr 0.000916 | 222.70 ms | loss 0.00970 | ppl     1.01\n",
            "| epoch  84 |   159/  269 batches | lr 0.000916 | 220.81 ms | loss 0.01005 | ppl     1.01\n",
            "| epoch  84 |   212/  269 batches | lr 0.000916 | 221.64 ms | loss 0.01051 | ppl     1.01\n",
            "| epoch  84 |   265/  269 batches | lr 0.000916 | 221.28 ms | loss 0.00973 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  84 | time: 64.82s | valid loss 0.01415 | valid ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  85 |    53/  269 batches | lr 0.000898 | 224.55 ms | loss 0.01145 | ppl     1.01\n",
            "| epoch  85 |   106/  269 batches | lr 0.000898 | 219.50 ms | loss 0.00958 | ppl     1.01\n",
            "| epoch  85 |   159/  269 batches | lr 0.000898 | 219.72 ms | loss 0.01045 | ppl     1.01\n",
            "| epoch  85 |   212/  269 batches | lr 0.000898 | 220.31 ms | loss 0.01089 | ppl     1.01\n",
            "| epoch  85 |   265/  269 batches | lr 0.000898 | 220.71 ms | loss 0.00982 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  85 | time: 64.35s | valid loss 0.01679 | valid ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  86 |    53/  269 batches | lr 0.000880 | 223.55 ms | loss 0.01230 | ppl     1.01\n",
            "| epoch  86 |   106/  269 batches | lr 0.000880 | 221.00 ms | loss 0.00930 | ppl     1.01\n",
            "| epoch  86 |   159/  269 batches | lr 0.000880 | 220.16 ms | loss 0.00984 | ppl     1.01\n",
            "| epoch  86 |   212/  269 batches | lr 0.000880 | 221.16 ms | loss 0.01048 | ppl     1.01\n",
            "| epoch  86 |   265/  269 batches | lr 0.000880 | 221.83 ms | loss 0.01016 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  86 | time: 64.57s | valid loss 0.01231 | valid ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  87 |    53/  269 batches | lr 0.000862 | 226.50 ms | loss 0.01153 | ppl     1.01\n",
            "| epoch  87 |   106/  269 batches | lr 0.000862 | 219.79 ms | loss 0.00923 | ppl     1.01\n",
            "| epoch  87 |   159/  269 batches | lr 0.000862 | 218.47 ms | loss 0.00970 | ppl     1.01\n",
            "| epoch  87 |   212/  269 batches | lr 0.000862 | 221.44 ms | loss 0.00996 | ppl     1.01\n",
            "| epoch  87 |   265/  269 batches | lr 0.000862 | 221.54 ms | loss 0.01014 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  87 | time: 64.52s | valid loss 0.01265 | valid ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  88 |    53/  269 batches | lr 0.000845 | 224.06 ms | loss 0.01123 | ppl     1.01\n",
            "| epoch  88 |   106/  269 batches | lr 0.000845 | 221.37 ms | loss 0.00960 | ppl     1.01\n",
            "| epoch  88 |   159/  269 batches | lr 0.000845 | 220.99 ms | loss 0.00945 | ppl     1.01\n",
            "| epoch  88 |   212/  269 batches | lr 0.000845 | 220.64 ms | loss 0.01008 | ppl     1.01\n",
            "| epoch  88 |   265/  269 batches | lr 0.000845 | 220.91 ms | loss 0.00924 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  88 | time: 64.56s | valid loss 0.01258 | valid ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  89 |    53/  269 batches | lr 0.000828 | 225.34 ms | loss 0.01123 | ppl     1.01\n",
            "| epoch  89 |   106/  269 batches | lr 0.000828 | 221.39 ms | loss 0.00937 | ppl     1.01\n",
            "| epoch  89 |   159/  269 batches | lr 0.000828 | 221.38 ms | loss 0.00914 | ppl     1.01\n",
            "| epoch  89 |   212/  269 batches | lr 0.000828 | 221.27 ms | loss 0.00980 | ppl     1.01\n",
            "| epoch  89 |   265/  269 batches | lr 0.000828 | 222.42 ms | loss 0.00925 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  89 | time: 64.83s | valid loss 0.01280 | valid ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  90 |    53/  269 batches | lr 0.000812 | 225.76 ms | loss 0.01106 | ppl     1.01\n",
            "| epoch  90 |   106/  269 batches | lr 0.000812 | 223.79 ms | loss 0.00941 | ppl     1.01\n",
            "| epoch  90 |   159/  269 batches | lr 0.000812 | 221.96 ms | loss 0.00999 | ppl     1.01\n",
            "| epoch  90 |   212/  269 batches | lr 0.000812 | 222.66 ms | loss 0.01011 | ppl     1.01\n",
            "| epoch  90 |   265/  269 batches | lr 0.000812 | 221.75 ms | loss 0.00861 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  90 | time: 68.81s | valid loss 0.01449 | valid ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  91 |    53/  269 batches | lr 0.000795 | 240.10 ms | loss 0.01224 | ppl     1.01\n",
            "| epoch  91 |   106/  269 batches | lr 0.000795 | 236.62 ms | loss 0.00924 | ppl     1.01\n",
            "| epoch  91 |   159/  269 batches | lr 0.000795 | 234.67 ms | loss 0.00985 | ppl     1.01\n",
            "| epoch  91 |   212/  269 batches | lr 0.000795 | 236.47 ms | loss 0.00973 | ppl     1.01\n",
            "| epoch  91 |   265/  269 batches | lr 0.000795 | 235.95 ms | loss 0.00887 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  91 | time: 68.66s | valid loss 0.01243 | valid ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  92 |    53/  269 batches | lr 0.000779 | 237.71 ms | loss 0.01064 | ppl     1.01\n",
            "| epoch  92 |   106/  269 batches | lr 0.000779 | 235.28 ms | loss 0.00893 | ppl     1.01\n",
            "| epoch  92 |   159/  269 batches | lr 0.000779 | 235.51 ms | loss 0.01009 | ppl     1.01\n",
            "| epoch  92 |   212/  269 batches | lr 0.000779 | 235.19 ms | loss 0.00955 | ppl     1.01\n",
            "| epoch  92 |   265/  269 batches | lr 0.000779 | 233.79 ms | loss 0.00897 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  92 | time: 68.29s | valid loss 0.01195 | valid ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  93 |    53/  269 batches | lr 0.000764 | 240.89 ms | loss 0.01057 | ppl     1.01\n",
            "| epoch  93 |   106/  269 batches | lr 0.000764 | 235.81 ms | loss 0.00918 | ppl     1.01\n",
            "| epoch  93 |   159/  269 batches | lr 0.000764 | 232.08 ms | loss 0.00966 | ppl     1.01\n",
            "| epoch  93 |   212/  269 batches | lr 0.000764 | 232.04 ms | loss 0.00939 | ppl     1.01\n",
            "| epoch  93 |   265/  269 batches | lr 0.000764 | 234.50 ms | loss 0.00927 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  93 | time: 68.19s | valid loss 0.01248 | valid ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  94 |    53/  269 batches | lr 0.000749 | 237.50 ms | loss 0.01084 | ppl     1.01\n",
            "| epoch  94 |   106/  269 batches | lr 0.000749 | 233.51 ms | loss 0.00911 | ppl     1.01\n",
            "| epoch  94 |   159/  269 batches | lr 0.000749 | 230.25 ms | loss 0.00887 | ppl     1.01\n",
            "| epoch  94 |   212/  269 batches | lr 0.000749 | 231.08 ms | loss 0.00902 | ppl     1.01\n",
            "| epoch  94 |   265/  269 batches | lr 0.000749 | 230.85 ms | loss 0.00849 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  94 | time: 67.47s | valid loss 0.01216 | valid ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  95 |    53/  269 batches | lr 0.000734 | 235.54 ms | loss 0.00995 | ppl     1.01\n",
            "| epoch  95 |   106/  269 batches | lr 0.000734 | 232.47 ms | loss 0.00930 | ppl     1.01\n",
            "| epoch  95 |   159/  269 batches | lr 0.000734 | 231.46 ms | loss 0.00926 | ppl     1.01\n",
            "| epoch  95 |   212/  269 batches | lr 0.000734 | 233.22 ms | loss 0.00902 | ppl     1.01\n",
            "| epoch  95 |   265/  269 batches | lr 0.000734 | 233.75 ms | loss 0.00843 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  95 | time: 67.69s | valid loss 0.01172 | valid ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  96 |    53/  269 batches | lr 0.000719 | 237.92 ms | loss 0.01019 | ppl     1.01\n",
            "| epoch  96 |   106/  269 batches | lr 0.000719 | 233.18 ms | loss 0.00855 | ppl     1.01\n",
            "| epoch  96 |   159/  269 batches | lr 0.000719 | 230.87 ms | loss 0.00909 | ppl     1.01\n",
            "| epoch  96 |   212/  269 batches | lr 0.000719 | 233.54 ms | loss 0.00898 | ppl     1.01\n",
            "| epoch  96 |   265/  269 batches | lr 0.000719 | 234.43 ms | loss 0.00837 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  96 | time: 67.89s | valid loss 0.01190 | valid ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  97 |    53/  269 batches | lr 0.000705 | 234.36 ms | loss 0.01011 | ppl     1.01\n",
            "| epoch  97 |   106/  269 batches | lr 0.000705 | 233.18 ms | loss 0.00852 | ppl     1.01\n",
            "| epoch  97 |   159/  269 batches | lr 0.000705 | 231.75 ms | loss 0.00912 | ppl     1.01\n",
            "| epoch  97 |   212/  269 batches | lr 0.000705 | 231.35 ms | loss 0.00898 | ppl     1.01\n",
            "| epoch  97 |   265/  269 batches | lr 0.000705 | 231.75 ms | loss 0.00828 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  97 | time: 67.42s | valid loss 0.01235 | valid ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  98 |    53/  269 batches | lr 0.000690 | 234.75 ms | loss 0.01038 | ppl     1.01\n",
            "| epoch  98 |   106/  269 batches | lr 0.000690 | 230.74 ms | loss 0.00808 | ppl     1.01\n",
            "| epoch  98 |   159/  269 batches | lr 0.000690 | 232.31 ms | loss 0.00909 | ppl     1.01\n",
            "| epoch  98 |   212/  269 batches | lr 0.000690 | 233.11 ms | loss 0.00889 | ppl     1.01\n",
            "| epoch  98 |   265/  269 batches | lr 0.000690 | 233.69 ms | loss 0.00788 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  98 | time: 67.59s | valid loss 0.01162 | valid ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  99 |    53/  269 batches | lr 0.000677 | 236.72 ms | loss 0.01003 | ppl     1.01\n",
            "| epoch  99 |   106/  269 batches | lr 0.000677 | 233.57 ms | loss 0.00834 | ppl     1.01\n",
            "| epoch  99 |   159/  269 batches | lr 0.000677 | 230.88 ms | loss 0.00876 | ppl     1.01\n",
            "| epoch  99 |   212/  269 batches | lr 0.000677 | 232.71 ms | loss 0.00837 | ppl     1.01\n",
            "| epoch  99 |   265/  269 batches | lr 0.000677 | 234.03 ms | loss 0.00850 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  99 | time: 67.77s | valid loss 0.01097 | valid ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch 100 |    53/  269 batches | lr 0.000663 | 235.95 ms | loss 0.01023 | ppl     1.01\n",
            "| epoch 100 |   106/  269 batches | lr 0.000663 | 232.58 ms | loss 0.00790 | ppl     1.01\n",
            "| epoch 100 |   159/  269 batches | lr 0.000663 | 232.40 ms | loss 0.00868 | ppl     1.01\n",
            "| epoch 100 |   212/  269 batches | lr 0.000663 | 234.91 ms | loss 0.00850 | ppl     1.01\n",
            "| epoch 100 |   265/  269 batches | lr 0.000663 | 233.64 ms | loss 0.00881 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch 100 | time: 71.54s | valid loss 0.01079 | valid ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jibf7dXKgVU_"
      },
      "source": [
        "PATH = \"Transformer_entire_model.pt\"\n",
        "torch.save(model, PATH)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_msZeV5gyPO",
        "outputId": "568fb403-b7ac-4700-a94f-e2b2064dd9ba"
      },
      "source": [
        "!ls "
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "daily-min-temperatures.csv  license.txt       Transformer_entire_model.pt\n",
            "docs\t\t\t    readme.md\t      transformer-multistep.py\n",
            "graph\t\t\t    requirements.txt  transformer-singlestep.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YU7a1F41gpwY"
      },
      "source": [
        "model = torch.load(PATH)\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUi6brKreN1f"
      },
      "source": [
        "src = torch.rand(input_window, batch_size, 1) # (source sequence length,batch size,feature number) \n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2_RRLWyeS8w"
      },
      "source": [
        "out = model(src)\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nscub_BjeWgo"
      },
      "source": [
        "print(out)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sguhp99netLu",
        "outputId": "792341ec-1446-4009-ce27-ad42e865534d"
      },
      "source": [
        "print(out.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100, 10, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-J1yEKHwejGp",
        "outputId": "f01bacbb-db58-4693-c95d-78a07bd889e2"
      },
      "source": [
        "print(src.shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100, 10, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ8YBBbVewXI"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "2d9pYZZ3e5Qe",
        "outputId": "00007a53-97b8-418d-8e7d-62ad01ed31e8"
      },
      "source": [
        "plt.plot(src[0,:,0])\n",
        "plt.plot(out.detach().numpy()[0,:,0])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fce36e09bd0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkteFNrsfNaA",
        "outputId": "31cf7f46-b1b6-4c1c-cebd-5eaa94c81ffe"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "daily-min-temperatures.csv  license.txt       transformer-multistep.py\n",
            "docs\t\t\t    readme.md\t      transformer-singlestep.py\n",
            "graph\t\t\t    requirements.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFgL02v7_iYj"
      },
      "source": [
        "#Push to Git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV_ICOHk7J0L"
      },
      "source": [
        "!git clone repo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhOi6bf67WM2"
      },
      "source": [
        "%cd repo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdZujRx6CBg-"
      },
      "source": [
        "!rm -r .git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtOrj4bICE4G"
      },
      "source": [
        "!git init"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKJZOzpi8NQ-"
      },
      "source": [
        "!git config --global user.email \"your_email\"\n",
        "!git config --global user.name \"your_username\""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-7_EX-V7dDx"
      },
      "source": [
        "!git commit -m \"new file\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYEk3y-Y9RLq"
      },
      "source": [
        "!git remote add origin https://your_username:your_password@github.com/abhiyantaabhishek/TransformerTimeSeries.git"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQMb3GuT8jCp"
      },
      "source": [
        "!git push origin master"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyKnTK7v9VSy"
      },
      "source": [
        "!git remote -v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91w0Ym789YiS"
      },
      "source": [
        "!git remote rm origin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRzfuiQFjcyB"
      },
      "source": [
        "#Copy to Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cpRQFdfjfZy",
        "outputId": "d98d59fd-3547-4f36-cee7-9d9f535d0b01"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArRSU6lijpkP"
      },
      "source": [
        "!cp -r  /content/transformer-time-series-prediction /content/drive/'My Drive'//transformer-time-series-prediction"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yGzyuIEjucX"
      },
      "source": [
        "drive.flush_and_unmount()"
      ],
      "execution_count": 53,
      "outputs": []
    }
  ]
}